import os
import json
import glob
import pandas as pd

BASE_PATH = os.path.join(os.getcwd(), "data")
PREDICTIONS_FILE = os.path.join(BASE_PATH, "latest_predictions.json")
NEWS_PATH = os.path.join(BASE_PATH, "processed_news")

def read_predictions():
    """Reads the JSON file generated by the ML pipeline."""
    if not os.path.exists(PREDICTIONS_FILE):
        return []
    try:
        with open(PREDICTIONS_FILE, "r") as f:
            return json.load(f)
    except Exception as e:
        print(f"Database Read Error: {e}")
        return []

def read_news(stock_symbol, limit=10):
    """Reads parquet news data for a specific stock."""
    try:
        files = glob.glob(os.path.join(NEWS_PATH, "**/*.parquet"), recursive=True)
        if not files:
            return []
        
        # Sort by modification time to get latest data first
        files = sorted(files, key=os.path.getmtime, reverse=True)[:5]
        
        df_list = []
        for f in files:
            try:
                df = pd.read_parquet(f)
                df_list.append(df)
            except:
                continue
        
        if not df_list:
            return []
            
        full_df = pd.concat(df_list)
        stock_news = full_df[full_df['stock'] == stock_symbol]
        
        if stock_news.empty:
            return []
            
        return stock_news.sort_values(by='published_at', ascending=False).head(limit).to_dict(orient="records")
        
    except Exception as e:
        print(f"Parquet Read Error: {e}")
        return []