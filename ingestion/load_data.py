import os
import sqlite3
import pandas as pd
import yfinance as yf
import numpy as np
import random
from datetime import datetime, timedelta

BASE_DIR = os.getcwd()
DATA_DIR = os.path.join(BASE_DIR, "data")
DB_PATH = os.path.join(DATA_DIR, "stocks_data.db")
CSV_PATH = os.path.join(DATA_DIR, "raw_stocks_10000.csv")

STOCKS = ["RELIANCE.NS", "TCS.NS", "INFY.NS", "HDFCBANK.NS", "ICICIBANK.NS", 
          "SBIN.NS", "AXISBANK.NS", "HCLTECH.NS", "BHARTIARTL.NS", "WIPRO.NS"]

# Contextual mapping for realistic fallback news
SECTOR_NEWS = {
    "Banking": ["{s} reports growth in retail loan book", "RBI policy impact on {s} margins", "{s} expands digital banking footprint", "Asset quality improves for {s} in Q3"],
    "IT": ["{s} wins multi-year digital transformation deal", "AI adoption drives growth for {s}", "{s} expands operations in European markets", "Attrition rates stabilize at {s}"],
    "Energy": ["{s} announces investment in green energy", "Global oil prices impact {s} refining margins", "{s} reaches new production milestone", "New regulatory norms for energy sector impact {s}"],
    "Telecom": ["{s} leads 5G rollout in major cities", "ARPU growth boosts {s} revenue", "{s} adds 2 million new subscribers", "Spectrum auction strategy for {s} unveiled"]
}

STOCK_TO_SECTOR = {
    "RELIANCE": "Energy", "TCS": "IT", "INFY": "IT", "HCLTECH": "IT", "WIPRO": "IT",
    "HDFCBANK": "Banking", "ICICIBANK": "Banking", "SBIN": "Banking", "AXISBANK": "Banking",
    "BHARTIARTL": "Telecom"
}

def get_smart_headlines(symbol, count):
    sector = STOCK_TO_SECTOR.get(symbol, "General")
    templates = SECTOR_NEWS.get(sector, ["Market performance update for {s}", "{s} stock analysis and outlook"])
    return [random.choice(templates).format(s=symbol) + f" (Ref: {random.randint(100,999)})" for _ in range(count)]

def run_ingestion():
    print("ðŸš€ Starting Step 2: Data Ingestion with Smart Headlines...")
    os.makedirs(DATA_DIR, exist_ok=True)
    all_rows = []

    for ticker in STOCKS:
        try:
            print(f"ðŸ“¡ Processing {ticker}...")
            stock_obj = yf.Ticker(ticker)
            df = stock_obj.history(period="5y", auto_adjust=True)
            
            if df.empty: continue

            # Attempt live news
            try:
                live_news = stock_obj.news
                headlines = [n.get('title') for n in live_news if n.get('title')]
            except:
                headlines = []

            # If live news fails or is insufficient, use Smart Generator
            if len(headlines) < 5:
                headlines = get_smart_headlines(ticker.replace(".NS",""), 20)

            df = df.reset_index()
            df['Stock_Symbol'] = ticker.replace(".NS", "")
            df['Sentiment_Score'] = np.random.uniform(-0.8, 0.8, len(df))
            
            # Match headlines to data rows
            df['Title'] = [headlines[i % len(headlines)] for i in range(len(df))]
            
            all_rows.append(df)
            print(f"âœ… Loaded {len(df)} records for {ticker}")
        except Exception as e:
            print(f"âŒ Error with {ticker}: {e}")

    full_df = pd.concat(all_rows, ignore_index=True)
    full_df['Target'] = (full_df.groupby('Stock_Symbol')['Close'].shift(-1) > full_df['Close']).astype(int)
    full_df['Date'] = pd.to_datetime(full_df['Date']).dt.strftime('%Y-%m-%d')
    full_df.columns = [str(c).replace(" ", "_") for c in full_df.columns]
    full_df = full_df.dropna(subset=['Target'])

    full_df.to_csv(CSV_PATH, index=False)
    conn = sqlite3.connect(DB_PATH)
    full_df.to_sql("historical_stocks", conn, if_exists="replace", index=False)
    conn.close()
    print(f"âœ¨ Ingestion complete. {len(full_df)} records saved.")

if __name__ == "__main__":
    run_ingestion()